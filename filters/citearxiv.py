################################################################################
#                                                                              #
#   This file is part of the Bibolamazi Project.                               #
#   Copyright (C) 2013 by Philippe Faist                                       #
#   philippe.faist@bluewin.ch                                                  #
#                                                                              #
#   Bibolamazi is free software: you can redistribute it and/or modify         #
#   it under the terms of the GNU General Public License as published by       #
#   the Free Software Foundation, either version 3 of the License, or          #
#   (at your option) any later version.                                        #
#                                                                              #
#   Bibolamazi is distributed in the hope that it will be useful,              #
#   but WITHOUT ANY WARRANTY; without even the implied warranty of             #
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the              #
#   GNU General Public License for more details.                               #
#                                                                              #
#   You should have received a copy of the GNU General Public License          #
#   along with Bibolamazi.  If not, see <http://www.gnu.org/licenses/>.        #
#                                                                              #
################################################################################

import re
import os
import os.path
import io
import arxiv2bib
from urllib2 import HTTPError

from pybtex.database import BibliographyData;
import pybtex.database.input.bibtex as inputbibtex;

from core.bibfilter import BibFilter, BibFilterError;
from core.blogger import logger;



HELP_AUTHOR = u"""\
Cite Arxiv IDs filter by Philippe Faist, (C) 2013, GPL 3+ (with code from Nathan Grigg (C) new BSD license)
"""

HELP_DESC = u"""\
Filter that fills BibTeX files with relevant entries to cite with \cite{1211.1037}
"""

HELP_TEXT = u"""
... write me ....

Note: uses code (arxiv2bib) by Nathan Grigg available at
https://github.com/nathangrigg/arxiv2bib

"""



class CiteArxivFilter(BibFilter):

    helpauthor = HELP_AUTHOR
    helpdescription = HELP_DESC
    helptext = HELP_TEXT

    def __init__(self, jobname, search_dirs=[]):
        """CiteArxivFilter constructor.

        Arguments:
          - jobname: the base name of the latex file. Will search for jobname.aux and look for
                     \citation{..} commands as they are generated by latex.
          - search_dirs(list): the .aux file will be searched for in this list of directories
        """

        BibFilter.__init__(self);

        self.jobname = jobname
        self.search_dirs = search_dirs

        if (not self.search_dirs):
            self.search_dirs = ['.', '_cleanlatexfiles'] # also for my cleanlatex utility :)

        logger.debug('citearxiv: jobname=%r' % (jobname,));


    def name(self):
        return "citearxiv"

    def getRunningMessage(self):
        return u"parsing & fetching relevant arxiv citations ..."

    
    def action(self):
        return BibFilter.BIB_FILTER_BIBOLAMAZIFILE;


    def filter_bibolamazifile(self, bibolamazifile):

        citearxiv_fetched_cache = self.cache_for('citearxiv_fetched_cache')['fetched'];

        logger.longdebug('fetched arxiv citations cache: %r: %r' %(citearxiv_fetched_cache.keys(),
                                                                   citearxiv_fetched_cache))

        #
        # First, find and analyze jobname.aux
        #

        allaux = None
        for maybeauxfile in (os.path.join(searchdir, self.jobname+'.aux') for searchdir in self.search_dirs):
            try:
                with open(maybeauxfile, 'r') as auxf:
                    allaux = auxf.read()
            except IOError:
                pass

        if (not allaux):
            raise BibFilterError(self.name(), "Can't analyze citations: can't find `%s.aux'." %(self.jobname))

        #
        # parse allaux for \citation{...}
        #
        arxiv_cites = [];
        
        for citation in re.finditer(r'\\citation\{(?P<citekey>[^\}]+)\}', allaux):
            citekey = citation.group('citekey')
            if (arxiv2bib.NEW_STYLE.match(citekey) or arxiv2bib.OLD_STYLE.match(citekey)):
                # this is an arxiv citation key
                arxiv_cites.append(citekey)

        #
        # Now, fetch all bib entries that we need.
        #

        missing_ids = []
        for arxivid in arxiv_cites:
            if arxivid not in citearxiv_fetched_cache:
                missing_ids.append(arxivid)

        # if there are missing ids, fetch them
        if (missing_ids):
            logger.longdebug('fetching id list %r' %(missing_ids))
            try:
                arxivdict = arxiv2bib.arxiv2bib_dict(missing_ids)
                logger.longdebug('got entries %r: %r' %(arxivdict.keys(), arxivdict))
            except HTTPError as error:
                if error.getcode() == 403:
                    raise BibFilterError(self.name(), textwrap.dedent("""\
                    403 Forbidden error. This usually happens when you make many
                    rapid fire requests in a row. If you continue to do this, arXiv.org may
                    interpret your requests as a denial of service attack.
                    
                    For more information, see http://arxiv.org/help/robots.
                    """))
                else:
                    raise BibFilterError(self.name(),
                        "HTTP Connection Error: {0}".format(error.getcode())
                        )
                
            for (k,v) in arxivdict.iteritems():
                citearxiv_fetched_cache[k]['reference'] = v;
                bibtex = v.bibtex();
                citearxiv_fetched_cache[k]['bibtex'] = bibtex;


        logger.longdebug('fetched arxiv citations cache: %r' %(citearxiv_fetched_cache))

        #
        # Now, include all the entries of citearxiv_fetched_cache into our database.
        #
        # Variable bibdata is a pybtex.database.BibliographyData object
        #

        thebibdata = bibolamazifile.bibliographydata();

        # join all the bibtex blocks of all the cached entries
        allbibtex = "\n".join( [ val['bibtex'] for k,val in citearxiv_fetched_cache.iteritems() ] );

        for arxivid, dat in citearxiv_fetched_cache.iteritems():
            # parse bibtex
            parser = inputbibtex.Parser();
            new_bib_data = None;
            with io.StringIO(unicode(dat['bibtex'])) as stream:
                new_bib_data = parser.parse_stream(stream);
            
            # and add them to the main list
            if (len(new_bib_data.entries.keys()) != 1):
                logger.warning("Got more than one bibtex entry when retreiving `%s'!" %(arxivid))

            for val in new_bib_data.entries.values():
                thebibdata.add_entry(arxivid, val);

        #
        # yay, done!
        #
        
        return


def bibolamazi_filter_class():
    return CiteArxivFilter;

